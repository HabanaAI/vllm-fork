[
    {
        "test_name": "latency_llama8B_tp1",
        "parameters": {
            "model": "/root/.cache/huggingface/hub/Meta-Llama-3-8B-Instruct",
            "tensor_parallel_size": 1,
            "load_format": "dummy",
            "num_iters_warmup": 5,
            "num_iters": 15
        }
    }
]
