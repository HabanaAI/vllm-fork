llama8b_default:
  MODEL: meta-llama/Llama-3.1-8B-Instruct
  MAX_MODEL_LEN: 2048
  TENSOR_PARALLEL_SIZE: 1
  VLLM_SKIP_WARMUP: true
  

llama8b_large:
  MODEL: meta-llama/Llama-3.1-8B-Instruct
  MAX_MODEL_LEN: 4096
  TENSOR_PARALLEL_SIZE: 4
  VLLM_SKIP_WARMUP: false
  BLOCK_SIZE: 32
  DTYPE: bfloat16
  GPU_MEMORY_UTILIZATION: 0.95

llama8b_experimental:
  MODEL: meta-llama/Llama-3.1-8B-Instruct
  EXPERIMENTAL_WEIGHT_SHARING: true
  PT_HPU_LAZY_MODE: 1
  VLLM_DELAYED_SAMPLING: true
  VLLM_GRAPH_PROMPT_RATIO: 0.5
  VLLM_GRAPH_RESERVED_MEM: 0.1
  VLLM_PROMPT_SEQ_BUCKET_MAX: 512
  VLLM_PROMPT_SEQ_BUCKET_STEP: 16
  VLLM_SKIP_WARMUP: true
  BLOCK_SIZE: 64
  DTYPE: float16
  GPU_MEMORY_UTILIZATION: 0.9
  MAX_MODEL_LEN: 8192
  MAX_NUM_PREFILL_SEQS: 128
  MAX_NUM_SEQS: 256
  PT_HPU_ENABLE_LAZY_COLLECTIVES: true
  GPU_MEM_UTILIZATION: 0.8