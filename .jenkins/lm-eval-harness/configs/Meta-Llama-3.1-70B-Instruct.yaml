# FIXME(kzawora): these scores were generated using vLLM on HPU, we need to confirm them on HF
# VLLM_SKIP_WARMUP=true bash .jenkins/lm-eval-harness/run-lm-eval-gsm-vllm-baseline.sh -m "/mnt/weka/data/pytorch/llama3.1/Meta-Llama-3.1-70B-Instruct" -b 128 -l 250 -f 5 -t 2
model_name: "/mnt/weka/data/pytorch/llama3/Meta-Llama-3.1-70B-Instruct"
tasks:
- name: "gsm8k"
  metrics:
  - name: "exact_match,strict-match"
    value: 0.928
  - name: "exact_match,flexible-extract"
    value: 0.884
limit: 250
num_fewshot: 5
dtype: "bfloat16"
