# These scores were chosen to place within 6% range of values achieved using  vLLM on HPU:
# 0.192 - 0.220
# where on https://www.llama.com/llama2/: 0.146 is given
model_name: "/mnt/weka/data/pytorch/llama2/Llama-2-7b-chat-hf"
tasks:
- name: "gsm8k"
  metrics:
  - name: "exact_match,strict-match"
    value: 0.206
  - name: "exact_match,flexible-extract"
    value: 0.206
limit: 250
num_fewshot: 5
dtype: "bfloat16"